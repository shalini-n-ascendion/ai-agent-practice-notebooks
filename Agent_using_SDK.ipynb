{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62XvXUZlKxVQ"
      },
      "outputs": [],
      "source": [
        "pip install -q google-generativeai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.userdata as userdata\n",
        "import google.generativeai as genai\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Pydantic models for tool arguments.\n",
        "class say_hi_validator(BaseModel):\n",
        "    \"\"\"Arguments for the 'say_hi' tool.\"\"\"\n",
        "    query: str = Field(description=\"The user's greeting message.\")\n",
        "\n",
        "class say_bye_validator(BaseModel):\n",
        "    \"\"\"Arguments for the 'say_bye' tool.\"\"\"\n",
        "    query: str = Field(..., description=\"The user's farewell message.\")\n",
        "\n",
        "# Your Python tools as regular functions.\n",
        "def say_hi(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this tool when the user greets you, says hello, or starts a conversation.\n",
        "    \"\"\"\n",
        "    return \"Hi!\"\n",
        "\n",
        "def say_bye(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this tool when the user wants to end the conversation or says goodbye.\n",
        "    \"\"\"\n",
        "    return \"Bye!\""
      ],
      "metadata": {
        "id": "T6sjXUSQK9C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure with your API key\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# The SDK automatically uses Pydantic models to create the tool schema.\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    tools=[say_hi, say_bye]\n",
        ")"
      ],
      "metadata": {
        "id": "uqCQRJIMLFuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# System instruction (prompting) to guide the model's behavior.\n",
        "system_instruction = ('''\n",
        "You are an assistant designed to use tools to respond to user requests.\n",
        "Your primary task is to carefully analyze the user's input and determine which of the available tools is most appropriate to accomplish their goal.\n",
        "\n",
        "If a tool is a perfect match, call it with the correct parameters.\n",
        "If no tool is suitable for the user's request, do not aexttempt to call any tool. Instead, respond directly with the exact phrase: 'You can do better!'\n",
        "''')\n",
        "\n",
        "\n",
        "# The conversational loop\n",
        "print(\"Agent is ready. Type 'exit' to end the conversation.\")\n",
        "for turn in range(10): # A for loop to limit the number of turns for this example\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Agent: Goodbye!\")\n",
        "        break\n",
        "\n",
        "   # Send the user's message to the model with the system instruction\n",
        "    response = model.generate_content(\n",
        "        [system_instruction, user_input]\n",
        "        )\n",
        "\n",
        "    # Check if the model's response contains a tool call\n",
        "    try:\n",
        "        tool_call = response.candidates[0].content.parts[0].function_call\n",
        "        tool_name = tool_call.name\n",
        "        tool_args = dict(tool_call.args)\n",
        "\n",
        "        print(f\"Agent chose to call tool: {tool_name} with arguments: {tool_args}\")\n",
        "\n",
        "        # Execute the tool using the mapped function and the validated arguments\n",
        "\n",
        "        tool_result = tools_map[tool_name](**tool_args)\n",
        "\n",
        "        # Print the tool's output to the user\n",
        "        print(f\"Agent: {tool_result}\")\n",
        "\n",
        "    except :\n",
        "        # This block runs if no tool was called. The model responded with text\n",
        "        print(f\"Agent: {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "bszwaPUPMr-a",
        "outputId": "d32dd5b3-65ee-4936-d2a0-baad40a8e5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent is ready. Type 'exit' to end the conversation.\n",
            "You: hi\n",
            "Agent chose to call tool: say_hi with arguments: {'query': 'hi'}\n",
            "Agent: Hi!\n",
            "You: bye\n",
            "Agent chose to call tool: say_bye with arguments: {'query': 'bye'}\n",
            "Agent: Bye!\n",
            "You: fgchvjbnm\n",
            "Agent: You can do better!\n",
            "\n",
            "You: exit\n",
            "Agent: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}